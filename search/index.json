[{"content":"写在前面 首先必须说明一点：对于内核而言，任何一种锁机制都是需要解决多核通信问题的。对于除了RCU锁以外的其他锁而言，它们最低的开销也至少是一对原子访存指令，核心数越多，其原子访存开销也会跟着以$O(N^2)$的级别增长。\n1. 自旋锁 spin_lock，最原始的自旋锁，通过一个atomic_bool的标记位指示是否有线程正在访问。\n不区分读写者，一旦获取到锁就相当于同时获取读写权限。\n优点：结构简单、能够极大程度保证原子性（事实上，你只需要把需要保证原子性的数据都放到同一个锁中即可） 缺点：在多读者、少写者的情况下效率低下。由于其本质是强制通过阻塞实现原子性，是一种舍弃并行性、通过串行损耗性能的行为。可以认为存在数据竞争的情况下，效率是所有锁里最低的。 适用于存在大量写者，或每次操作都需要同时获取读写权限的情况。\n1.1 票锁 ticket_lock是一种公平的自旋锁，在自旋等待阶段，通过队列等方式实现先来先得式的仲裁功能。\n2. 读写锁 rw_lock，通过一个atomic_usize指示当前锁中读者的个数，正数表示有若干读者，-1表示当前存在写者占用。\n读写锁中，写者优先级低于读者，必须等到读者全部释放，也就是原子计数被置为0之后，才有机会让写者访问。\n读写锁的优缺点都很明显：\n优点：能够满足最高效率的读请求。\n缺点：如果不对读写操作的顺序加以限制的话，比方说若干读操作占用锁的时间覆盖了大量时间段，那么大概率会造成写者的饥饿。\n3. 顺序锁 seq_lock，融合了自旋锁和读写锁的优势，实现了多读者+单写者的情况，其实现非常优美。\n思路 观察上面自旋锁和读写锁的缺点，我们有如下需求：\n尽量提高写者的优先级，避免写者饥饿 尽量减少读者访问数据的开销，避免在无写者的情况下产生额外的自旋开销 基本思想：当读者访问锁的时候，假如访问期间不存在写者修改数据，那么可以认为读取的数据是正确的。所以，只需要通过原子访存机制，让读者检测读取过程中是否发生写操作即可。\n实现 seq_lock通过一个atomic_usize进行写者状态的计数，实现了对于读操作期间的写操作检测。\n具体而言，当写者进入临界区时原子计数cnt++，退出临界区时再次cnt++，并通过自旋锁保证同一时刻只存在一个写者。\n而对于读者而言，只会存在下面两种需要阻塞等待的情况：\n当cnt的值为奇数时，表明存在写者正在访问临界资源，读者无法访问； 当读者检测到读取前后cnt的值发生改变的时候，表明在读取时间内发生了写者的访问，需要重新进行读取。 而如果不发生写操作，则读者的访问开销只有对于原子计数进行的两次数值比较，相较于之前的阻塞式自旋效率大幅提升。\n优点：避免了多读者、无写者情况下的数据竞争。\n缺点：存在写者的情况下，仍然等效于自旋锁行为。此外，读者仍然需要执行原子访存。\n4. RCU锁 对于n核竞争的情况，原子访存会导致n次对于n个核心的invalidate操作，因此这个操作会产生$O(N^2)$的无效化开销。在我们的上面三种基于原子访存的锁机制当中，都会存在这个多核之间的无效化开销，从而产生巨大的原子访存开销。（存疑）\nRCU锁的使用场景是多核、多读者、少写者的情况，并且只适用于如链表维护的链/树形结构等通过能够通过指针进行明确拆分的、所谓的”可持久化“的数据结构。它通过内存屏障而不是原子指令实现，因此不会产生原子访存的$O(N^2)$的缓存无效化开销，这对于多核场景而言非常友好。\n思路 我们引入RCU的最开始目的是尽可能地避免原子访存。那么思考一下，为什么自旋锁需要进行原子访存？\n答：因为写者存在时，它与读者共享了同一份数据，所以需要向读者传递“写者是否存在“这一个信息。而传递写者的存在就需要原子访存来维护多核一致性了。\n所以首要的目的就是，需要让写者对于读者而言变为透明，因此写者不能与读者共享同一份数据。\n基于这种想法，我们可以想到解决方案：在写者执行写操作的时候开辟一段新的内存区域，用于存放写入的数据；而旧值仍然保留（因为它们可能正在被读者访问），直到所有旧值区域的读者读取完毕之后，再由写者将旧值的内存进行释放。\n这是一种类似可持久化线段树或寄存器重命名的思想，通过保存多份同一对象的不同历史数据，实现了可变数据对于读者的只读性。在这种情况下， 任何数据一旦被写者初始化完成，就一直处于只读状态，不会有写者再来对它进行更改，因此读者也不需要对于写者进行任何的检测。\n这种实现下，所有的资源管理的功能都交给了写者，而读者只需要在访问资源之前执行内存屏障，防止读取到未被写入的数据即可。而对于写者而言，它需要通过某种方式监听旧数据读者的状态，并在读者访问完毕之后对资源进行回收。\n实现 RCU锁最难的地方就是写者对旧数据的资源回收过程。天才的做法：令持有读锁的线程关闭内核抢占，并限制在让权的时候，线程一定不能持有RCU读锁。则如果硬件线程发生了上下文切换，那么该硬件线程一定在此之前释放了旧的RCU锁。\n那么，写者只需要等待所有硬件线程都发生一次上下文切换，就能够保证旧数据中不再存在读者了！\n天才一样的想法！将细粒度、小概率、性能敏感事件归属到粗粒度、大概率、性能不敏感事件当中，实现了相对较小的数据同步开销。\n个人想法 相较于上面三种精简小巧、基于原子指令的锁，RCU锁是完全不同的一类锁，RCU结构更复杂，会依赖于操作系统层面的context switch相关的代码。我认为RCU lock是一个与操作系统耦合的锁，很难单独解耦成库。\n其实RCU锁的具体实现我没有太看懂，但大概就是这样了，只是提供一点自己的理解。\n","date":"2025-04-06T00:00:00Z","image":"https://crpboy.github.io/p/os-linux-locks/cover_hu17113026730877005545.png","permalink":"https://crpboy.github.io/p/os-linux-locks/","title":"Linux锁机制 - 从自旋锁到RCU锁"},{"content":"基于Future的Rust操作系统内核异步编程 2024/11/14 by crpboy\n前言 本文是有关使用async_task进行操作系统内核异步编程的解析, 不涉及tokio运行时的解析.\n建议先阅读官方文档了解基础的异步编程语法.\nrust使用async和await进行异步编程, 其底层实现为Future特性, 具体语法不再赘述.\n可以参考官方文档. Rust语言圣经 Rust 中的异步编程.\nasync 在rust当中, async是使用无栈协程机制 (关于无栈协程, 可以看这个视频) 实现的, 其内部是一个状态机, 下面我将通过一个例子来说明.\n观察下面这个函数, 其中func_1/2/3都是异步函数, 可能无法立即得到返回.\n1 2 3 4 5 6 7 8 9 async fn func_main() { println!(\u0026#34;process 1\u0026#34;); func_1().await; println!(\u0026#34;process 2\u0026#34;); func_2().await; println!(\u0026#34;process 3\u0026#34;); func_3().await; println!(\u0026#34;process 4\u0026#34;); } 异步函数可以被转化为一个状态机模型. 本例中, 异步函数被三个.await语句拆分成为了四个部分, 每个.await都有 完成 / 等待 两种执行结果, 将它上下的执行部分通过 完成 / 等待 这两条状态转移边连接起来.\n画个图就很清楚了.\n假如子函数func_n能够执行完毕, 那就推动当前状态机进度, 从process_n走到process_n+1, 否则当前函数就阻塞在了func_n, 我们可以考虑让权, 等func_n满足恢复执行的条件了, 再去尝试推动函数进展. 关于让权和恢复的过程, 我会在后续的执行器部分详细说明.\nFuture 事实上, async fn是Future的一个语法糖, 它上将原函数包装为了一个带有Future特性的匿名类.\n为了深入了解, 我们得来看一下Future的具体定义:\n1 2 3 4 5 6 7 8 pub trait Future { type Output; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt;; } pub enum Poll\u0026lt;T\u0026gt; { Ready(T), Pending, } Future的关键是poll函数, 它会通过返回Poll::Ready(T)或Poll::Pending向上级函数反馈当前Future的执行情况信息. 而关于Future.poll的具体用法, 大部分的教材都是这么说的:\n你可以通过对带有Future特性的类调用poll来尝试\u0026quot;推动它的进展\u0026quot;\n什么叫\u0026quot;推动进展\u0026quot;? 其实就是在Future对应的状态机上, 尝试从上一个状态转移到下一个状态.\n如果子函数 (严格来说是子Future, 下略) 返回了Ready, 当前函数会流畅地继续执行下去.\n如果子函数返回了Pending, 那么当前函数调用链都会逐级返回Pending, 因此整条函数调用链被阻塞, 一般会在这里选择让权等待.\n一个异步函数内的.await调用相当于对于子函数进行一次poll的调用, 假如子函数阻塞在了Pending状态, 那么后续将通过执行器重新进行poll调用直到返回Ready为止.\nWaker Waker与Context的关系 在上文当中我刻意省略了有关poll中的Context参数的内容. 目前Context当中只有Waker被真正使用, 所以可以暂时认为Context和Waker是等价的. 官方也在文档里说明了这一点.\n现在让我们回过头来重新看一下poll函数:\n1 fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt;; 这个传入的cx就是用于传递Waker信息的, 我们可以通过cx.waker()将内部的Waker取出进行调用.\n那么Waker到底是用来干什么的呢? 很多教材都会说这是个\u0026quot;唤醒器\u0026quot;. 但什么时候需要唤醒? 唤醒的对象是谁? 什么时候需要保存唤醒器? 唤醒信号是如何通知的? 唤醒的具体过程又是如何? 一概不知.\n问题太多, 所以我们先按下不表, 必须等完整的了解Waker和Executor的实现之后, 才能够解答这个问题.\nWaker的实现 接下来让我们来看看Waker的定义:\n1 2 3 4 5 6 7 8 pub struct Waker { waker: RawWaker, // ignore phantom data } pub struct RawWaker { data: *const (), vtable: \u0026amp;\u0026#39;static RawWakerVTable, } 可以发现Waker的内部实现为RawWaker, RawWaker内部保存了data和vtable.\ndata用于保存Waker对应的任务的相关数据, 在async_task当中, 它指向了RawTask这个结构体, 其中保存了一个任务的所有信息, 可以用于后续状态的恢复.\nvtable保存了一个\u0026amp;'static RawWakerVTable的指针, 我们来看看内部实现:\n1 2 3 4 5 6 pub struct RawWakerVTable { clone: unsafe fn(*const ()) -\u0026gt; RawWaker, wake: unsafe fn(*const ()), wake_by_ref: unsafe fn(*const ()), drop: unsafe fn(*const ()), } 可以看到, vtable内部保存着四个函数指针, 对应了waker的四个基本函数. 但这四个函数的具体实现取决于waker对应的运行时环境. 在调用Waker.wake_by_ref()等函数的时候, 就会从vtable当中取出对应的函数入口进行执行.\n我们以async_task库为例, 在async_task当中, 会在创建一个Task的时候, 在内部创建一个链接着它自定义实现的上述四个函数入口的vtable, 并在创建waker的时候, 将vtable传递给waker.\n这样Waker就可以通过调用cx.waker().wake_by_ref()等函数, 使用async_task自定义的方法来进行唤醒了.\n至此我们也可以知道前文当中, 为什么关于Waker会产生这么多的疑惑: 因为Waker的内部函数实现取决于它使用的运行时库的实现, 不同的库的调度策略并不一致. 所以, 接下来我将对于async_task运行时及其对应的Executor实现进行进一步的解释.\nExecutor Executor的典型实现 与Future和Waker等Rust原生类不同, 在内核编程当中Executor是需要自己进行实现的, 更具体地来说, 你需要给出执行器的调度策略, 但并不需要关心内部的执行流程.\n下面是一个典型的async_task下的执行器的实现, 使用了双端队列进行维护. 其中spawn函数用于生成一个新任务, run用于执行任务.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 //! executor.rs struct Executor { queue: Mutex\u0026lt;VecDeque\u0026lt;Runnable\u0026gt;\u0026gt;, } impl Executor { pub fn new() -\u0026gt; Self { Self { queue: Mutex::new(VecDeque::new()), } } fn push_back(\u0026amp;self, runnable: Runnable) { self.queue.lock().unwrap().push_back(runnable); } fn push_front(\u0026amp;self, runnable: Runnable) { self.queue.lock().unwrap().push_front(runnable); } fn pop_front(\u0026amp;self) -\u0026gt; Option\u0026lt;Runnable\u0026gt; { self.queue.lock().unwrap().pop_front() } } lazy_static! { static ref EXECUTOR: Executor = Executor::new(); } /// Add a task into task queue pub fn spawn\u0026lt;F, R\u0026gt;(future: F) where F: Future\u0026lt;Output = R\u0026gt; + Send + \u0026#39;static, R: Send + \u0026#39;static, { let schedule = move |runnable: Runnable, info: ScheduleInfo| { if info.woken_while_running { EXECUTOR.push_back(runnable); } else { EXECUTOR.push_front(runnable); } }; let (runnable, handle) = async_task::spawn( future, WithInfo(schedule), ); runnable.schedule(); handle.detach(); } /// run next task pub fn run() { if let Some(runnable) = EXECUTOR.pop_front() { runnable.run(); } } executor::spawn 我们来看生成一个新任务的过程.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 pub fn spawn\u0026lt;F, R\u0026gt;(future: F) where F: Future\u0026lt;Output = R\u0026gt; + Send + \u0026#39;static, R: Send + \u0026#39;static, { let schedule = move |runnable: Runnable, info: ScheduleInfo| { if info.woken_while_running { EXECUTOR.push_back(runnable); } else { EXECUTOR.push_front(runnable); } }; let (runnable, handle) = async_task::spawn( future, WithInfo(schedule), ); runnable.schedule(); handle.detach(); } 首先, 我们通过定义schedule闭包, 定义了当前执行器的调度策略. 请注意, 在async_task当中, 所有的执行器调度都是通过这个schedule发生的, async_task内部向executor传递调度信息的唯一方式, 就是通过这个schedule.\n然后, 通过调用async_task::spawn, 可以生成一个新的任务, 其中就传入了schedule作为调度策略.\n1 let (runnable, handle) = async_task::spawn(future, WithInfo(schedule)); 这里的async_task::spawn会返回两个返回值, 它们的类型分别为Runnable和Task\u0026lt;future::Output\u0026gt;.\n我们查看async_task::spawn的内部实现, 会发现它最终是由内部的Builder.spawn_unchecked函数进行实现的:\n1 2 3 4 5 6 7 8 9 10 11 //! Builder.spawn_unchecked // 通过future和schedule创建一个RawTask, 再把RawTask的信息转为指针返回 let ptr = RawTask::\u0026lt;Fut, Fut::Output, S, M\u0026gt;::allocate(future, schedule, self); // 通过ptr创建runnable let runnable = Runnable::from_raw(ptr); // 通过ptr创建task let task = Task { ptr, _marker: PhantomData, }; (runnable, task) 在函数内部, 会调用RawTask::allocate来进行RawTask的生成. 查看RawTask发现, RawTask是真正保存了任务的所有信息的结构体:\n1 2 3 4 5 6 7 8 9 10 pub(crate) struct RawTask\u0026lt;F, T, S, M\u0026gt; { /// The task header. pub(crate) header: *const Header\u0026lt;M\u0026gt;, /// The schedule function. pub(crate) schedule: *const S, /// The future. pub(crate) future: *mut F, /// The output of the future. pub(crate) output: *mut Result\u0026lt;T, Panic\u0026gt;, } 而当RawTask生成完毕之后, 会通过ptr传回一个指针以供Runnable和Task创建.\n可以看出, Runnable和Task 都从同一个ptr创建而来, 是对同一个RawTask的两种不同的数据保存形式.\n事实上, Runnable保留了使用者与任务的信息交互接口, 在我们实际交互的时候, 通常都是调用Runnable的接口完成\n而Task用于保存任务实际的执行环境信息, 在本文中, 使用的时候我们不会直接对它进行修改.\nexecutor::run 及 schedule 的调用方式 先来回顾一下执行器执行的过程\n1 2 3 4 5 6 /// run next task pub fn run() { if let Some(runnable) = EXECUTOR.pop_front() { runnable.run(); } } 我们发现, 每一次运行run, 程序都会从执行器的双端队列队首通过pop_front取出一个待执行的Runnable对象, 尝试对它进行执行. 这里在内部实现上就是对于runnable对应的Future调用了一次poll轮询.\n那么问题来了, 有pop_front就应该有push. 我们目前的代码里, 唯一涉及向队列push的操作, 就只有schedule当中的push_front和push_back. 那么schedule一定在run函数被调用后的某处也跟着一起被调用了才对.\n但奇怪的是, 在run函数当中压根就没有对于schedule的调用操作. 事实上, 就算进入Runnable.run内部寻找, 也并没有对于schedule函数的直接调用. 那么schedule到底在哪里被调用了呢?\n最终我们在Task的wake函数实现当中找到了如下代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 match (*raw.header).state.compare_exchange_weak( state, state | SCHEDULED, Ordering::AcqRel, Ordering::Acquire, ) { Ok(_) =\u0026gt; { // If the task is not yet scheduled and isn\u0026#39;t currently running, now is the // time to schedule it. if state \u0026amp; RUNNING == 0 { // Schedule the task. Self::schedule(ptr, ScheduleInfo::new(false)); } else { // Drop the waker. Self::drop_waker(ptr); } break; } Err(s) =\u0026gt; state = s, } 这段代码尝试通过修改SCHEDULED标志位为1, 并在修改成功之后对任务调用schedule, 以此将其插入到执行队列当中. 至此我们终于找到了调用schedule的源头——wake函数.\n而这个wake函数, 就是被链接到Waker的vtable里的那个wake函数! 换句话来说, 插入执行队列的操作最终是由Waker.wake来完成的.\n很有趣, 找了一圈居然重新找到了先前Future::poll里传入的Waker上! 想要将任务重新恢复到执行器里, 靠的正是唤醒器的唤醒操作, 确实很合理.\n重归Waker 现在, 是时候重新回到Waker, 解答我们之前的疑问了.\n调用waker::wake的时机 Waker::wake的调用时机是怎样的呢? 我们来回顾一下Future::poll吧:\n1 fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt;; Context当中包含了Waker信息, Waker通过poll调用链上逐级传递下去. 一旦出现需要返回Pending的情况, 那么当前的执行过程就不得不中止了. 这种情况下, 对于waker有两种可能的操作:\n保存当前的Waker, 等待当前状态能够进一步推进的时候, 调用waker将其放入执行器的队首使其快速恢复执行. 直接再次唤醒Waker, 将对应的任务插入到执行器的队尾. 这两种处理方式在实践的时候都有使用, 前者一般用于IO密集型任务, 会在IO信号到来的时候通过先前Pending时保存的waker进行唤醒; 而后者一般用于普通的任务调度过程, 实现了一个较为传统的队列维护过程.\nwaker到底唤醒了谁 / 从哪来 这个问题还需要进一步的探讨. 为了研究清楚这个问题, 我写了一段嵌套调用Future然后返回Pending的代码, 发现每次poll的时候都会经历一次完整的函数调用链.\n所以我们可以得出结论: 每一次尝试poll的时候都会从根Future出发, 经历一次完整的poll调用链, 直到最深层返回Pending或者Ready为止.\n这也很好解释, 因为我们的Waker是逐级向下传递的, 保存的就是最开始Future.poll时传入的Waker. 所以每次尝试唤醒的时候也会调用这个传递下来的Waker.\n那么这个初始的Waker又是怎么传入的? 查看async_task::run, 发现是在run的过程当中调用poll时传入的. 回顾一下, Waker内部其实就是vtable和一个指向RawTask的指针, 所以这个Waker的生成是很方便的.\n总结 至此, 我们终于搞明白了一个完整的执行流程当中, 任务的信息是如何被传递的:\n任务以Future参数形式传入spawn函数 spawn函数通过Future生成RawTask, 再通过RawTask派生出Runnable和Task 先调用一次runnable.schedule, 将任务插入到执行器队列当中, 至此进入执行器执行的过程当中 执行器进行一次执行, 先将Runnable形态的任务从队首取出 对于取出的Runnable调用它的run函数, run内部会对它对应的Future调用一次poll, 并传入携带有自身wake函数实现方式的Waker信息 假如在执行过程当中遇到了一次Pending状态的传回, 那么当前任务需要阻塞, 同时需要保存Waker便于下次唤醒 在适当的时机 (比如某些信号来临的时候) 重新取出先前保存的Waker信息, 调用其中的wake函数 wake函数会通过Task::wake调用schedule函数, 最终通过schedule函数将任务信息重新插入回到任务执行队列当中. 至此实现了任务的循环调用过程. 完结撒花~\n","date":"2024-11-14T00:00:00Z","image":"https://crpboy.github.io/p/os-future/cover_hu12148202137344401275.jpg","permalink":"https://crpboy.github.io/p/os-future/","title":"基于Future的Rust操作系统内核异步编程"},{"content":"项目链接\n概况 本次NSCSCC比赛，我们NoAXI团队取得了二等奖，使用乱序双发射实现CPU，IPC为0.78，频率为83MHz。\n比较遗憾的是，我们没有在规定的时间内成功启动Linux系统，导致我们最终的系统成绩分偏低。所幸答辩成绩还算过关，最终顺利拿到了二等奖。\n心路历程 我们团队一开始都是打个人赛的，直到6月中旬才决定转成团队赛。所以我必须得介绍一下我们团队在组队之前的神奇经历。\n我在3月底开始接触的龙芯杯，先花了半个月时间，配置环境并且学习chisel的语法。大概到了4月中旬的时候，我写出了一个最朴素的顺序五级流水。此后就在此基础上不断完善，一直到6月份写到了Cache和TLB的开发。当时并不知道个人赛会有这么多简化，直到6月份自己做到了TLB才发现，已经走的太远了。我们的AXI状态机和TLB都没法用在个人赛当中，只能去团队赛了。\n于是果断转团队赛，跟涛哥一起组了NoAXI队。从6月中旬开始，我花了一周时间啃完了《超标量》并设计了乱序的基础结构。考试周期间比较忙，一直到7月份才有空写代码。我们团队从零开始，完全抛弃了原有的5级流水线设计，重写了一份乱序的代码，我主要负责的就是乱序架构相关的内容。大概到了7月中旬，终于成功地跑通了仿真。\n但是当时我们因为DCache中SRAM实现上的问题，出现了仿真通过，上板未通过的情况。我们前后花了一周的时间去debug，在vivado里面拉debug信号进行调试，一跑就是两个小时，可以说是非常痛苦。\n调完bug之后，我们的初赛也差不多相当于准备完毕了。此后我跑去起SoC，涛哥则准备启动linux。原本我设想的是起一个往年一等奖级别的定制化SoC，能够启动大部分的外设的，但因为驱动相关的原因，我最终没有成功启动以太网口，只能使用官方提供的SoC。我们最后的Linux也因为分支预测一致性问题而启动失败。可以说决赛相关的工作我们几乎全军覆没。\n最后两天我们连续熬了两个通宵，改了起Linux过程中的五六个bug，但最终差临门一脚，没有成功。算是留下了挺多的遗憾。\n启示，反思和总结 我们最终的设计版本其实很早就设计完毕了，但最终我们在访存相关的维护上面花了非常多的时间，尤其是访存的唤醒信号时延和一致性维护问题。我也希望，读到这篇文章的人在设计乱序CPU后端访存部件的时候，务必注意这些问题。\n其实很多东西，不去实操是绝对不会懂得的。永远不要想当然，永远不要去优化自己猜想的路径，而应该根据数据进行优化。我在做访存之前，甚至想象过访存是一个与算术流水线差不多复杂度的东西，这使得我们在设计推测唤醒和优化时序的时候付出了惨重的代价。我们的唤醒也做得有点问题，我把一个串行逻辑写了进去，导致我最终无法把访存的推测唤醒加到里面去。这些问题很大程度上都是我想当然导致的。\n说实话，我们这次比赛全程都在和时间赛跑，DDL一个接着一个地来，把我压的喘不过气来。6月中旬开始做乱序，8月中旬就要决赛提交，2个月的时间对于我们来说实在是太短了。我不止一次地想，如果再多给我们一个星期，说不定就能有新的转机了呢。但不论如何，我们既然做了乱序，就必须克服乱序带来的诸多设计难题。赶不上DDL也只能说是情有可原。\n希望明年学弟加油吧，争取不留遗憾。\n","date":"2024-09-03T00:00:00Z","image":"https://crpboy.github.io/p/nscscc-2024-summary/cover_hu17938661769826131365.jpg","permalink":"https://crpboy.github.io/p/nscscc-2024-summary/","title":"NSCSCC2024 赛后总结"},{"content":"项目链接\n1. 概述 1.1 项目简介 本项目是第八届\u0026quot;龙芯杯\u0026quot;全国大学生计算机系统能力培养大赛（NSCSCC 2024）的参赛作品。\n本项目为基于龙芯架构32位精简版指令集(LA32R)，开发的一款乱序多发射的CPU。项目基于Tomasulo动态调度算法，使用ROB重排序缓存，实现了一个乱序执行、后端四发射的CPU，最深级数到达了13。此外，我们还实现了分支预测、Cache缓存等诸多特性。我们在官方提供的性能测试框架当中，达到了0.78的IPC，I/DCache的命中率均达到了**98.8%**以上，使得CPU取得了良好的性能表现。\n1.2 处理器总体参数 我们非常关注处理器执行指令的效率，因此，下面将给出我们CPU在执行官方提供的性能测试框架时的相关参数概览。\n从下表可以看到，我们的I/D-Cache达到了98%以上的高命中率，优秀的访存维护逻辑使得我们的CPU在访存密集型测试集当中保持了良好的IPC。同时我们的分支命中成功率也达到了91.4%，这使得我们的CPU能够尽可能地避免分支预测失败带来的大量气泡，为我们加深流水级、实现后端乱序执行打下了良好的基础。\n项目 参数 IPC 0.78 频率 83hz 分支预测成功率 91.4% I-Cache命中率 99.6% D-Cache命中率 98.8% 流水级数 13 1.3 实现功能 我们的指令集支持了龙芯架构32位精简版中除了浮点指令以外的所有指令，并支持了指令集中全部CSR寄存器的维护，实现了丰富的指令功能。\n算数类指令：ADD.W, SUB.W, ADDI.W, LU12I.W, SLT[U], SLT[U]I, PCADDU12I, AND, OR, NOR, XOR, ANDI, ORI, XORI, MUL.W, MULH.W[U], DIV.W[U], MOD.W[U], SLL.W, SRL.W, SRA.W, SLLI.W, SRLI.W, SRAI.W 跳转指令：BEQ, BNE, BLT[U], BGE[U], B, BL, JIRL 访存指令：LD.B, LD.H, LD.W, LD.BU, LD.HU, ST.B, ST.H, ST.W,LL,SC CSR相关指令：CSRRD, CSRWR, CSRXCHG Cache相关指令：CACOP TLB相关指令：TLBSRCH, TLBRD, TLBWR, TLBFILL, INVTLB 栅障指令：IBAR,DBAR 其他杂项指令：RDCNTVL.W, RDCNTVH.W, RDCNTID, SYSCALL, BREAK, ERTN 2. 处理器微架构设计 2.1 整体介绍 NoAXI处理器采取前后端设计，前端共5个流水级，后端共6个流水级，共11个流水级，最深级数为13。\n前端五个流水级，分别为 预取指、取指、预译码、译码、重命名。\n后端分为六个流水级，分别为 分发、发射、读寄存器、执行、写回、提交。\n其中执行级分为并行的四条流水线，分别为：算术流水线0、算术流水线1、乘除流水线、访存流水线。\n前端采取顺序双发射设计，取指宽度为2，每个周期可以向后端最多传输2条指令。\n后端采取乱序四发射设计，流水线条数为4，每个周期可以进行最多2条指令的提交。\n2.2 前端设计 前端分为 预取指（PreFetch）、取指（Fetch）、预译码（PreDecode）、译码（Decode）、重命名（Rename） 共五级。\n其中，预译码级与译码级之间，使用了一个指令缓冲（Instruction Buffer）进行解耦。\n2.2.1 预取指 PreFetch 在这一级中进行pc的更新，并且将虚地址发送给TLB。\npc发送至TLB，TLB进行翻译 若是直接地址翻译或直接地址映射，直接将得到的物理地址传递给Fetch级 若是映射地址翻译，给TLB表项发地址，得到命中信息并传递给Fetch级 pc发送至I-Cache，基于VIPT原理，给I-Cache索引 pc发送至BPU，进行分支预测(发送按双字对齐的两个pc进行预测，如果第二个pc不满足双字对齐则不预测) pc发送至BTB读取信息 pc发送至BHT得到跳转历史，寄存器锁存供下一拍使用 根据情况更新pc (最高优先级)后端传来的跳转请求：可能是例外中断造成的跳转，也可能是特权指令需要冲刷流水线，也可能是分支预测失败的重新取指 (第二优先级)分支预测传来的跳转请求 (第三优先级)更新pc为按双字对齐的下一个pc，例如 1c001000 $\\rightarrow$ 1c001008，1c00110c $\\rightarrow$ 1c001110 2.2.2 取指 Fetch 为降低硬件复杂度，我们设计了独特的取指方式，选择双字对齐方式的双指令取指。相较于四指令取指，这样的取指方式降低了因分支预测造成的标记无效指令的硬件开销，并且，效率也不会得到大幅降低，因为我们的I-Cache一行存四个指令，大部分正常取指的情况下，两次取指中的第二次是必定命中I-Cache的，保证了前端取指的高效。\n在此级中把命中信息发送至TLB，读出命中表项，翻译出paddr；并且判断是否存在TLB相关例外 将得到的paddr发送至I-Cache，判定是否命中，若不命中则进入阻塞状态，并与主存利用axi接口交互取出Cache缺失行 取出两条指令，并且保证pc是按双字对齐的，若第二条指令pc未满足条件则会标记为无效 得到分支预测的结果 利用上一拍得到的BTB信息和BHT中读取到的BHR，得到预测方向和跳转结果 若预测跳转，清刷prefetch并对其发出跳转请求 2.2.2.1 分支预测器 BPU 在乱序处理器当中，因为流水级数深，分支预测失败代价过大。因此，分支预测器很大程度上决定着cpu的IPC。\n为降低硬件复杂度，我们同样设计了两级BPU，将整个预测过程分为了两拍完成。我们使用了基于局部历史的饱和计数器分支预测结合BTB和RAS对多种分支场景进行了有效的分支预测，下表是性能测试中十个测试点的具体成绩。\n测试点编号 测试点名称 无RAS分支预测成功率 分支预测成功率 1 bitcount 80.510 % 94.509 % 2 bubble_sort / 84.935 % 3 coremark / 88.955 % 4 crc32 90.100 % 96.367 % 5 dhrystone / 95.331 % 6 quick_sort / 74.780 % 7 select_sort / 93.456 % 8 sha / 98.284 % 9 stream_copy / 95.924 % 10 stringsearch / 93.666 % BHT(Branch History Table)：保存跳转指令的跳转局部历史，在跳转指令提交时更新\nPHT(Pattern History Table)：记录跳转历史对应的饱和计数器值，对应跳转的方向趋势，用于预测跳转方向\nBTB(Branch Target Buffer)：记录pc对应的跳转地址，兼顾判断跳转类型(CALL,Return,其他)的职责\n适用指令：条件跳转类和CALL型指令 用途：记录指令的跳转类型，是否为跳转指令(valid位)，跳转地址 仅当BTB命中时才可能发生分支预测 表项组织形式如下： Valid Tag Target Br_type 1 b (32 - index) b 32 b 2 b RAS(Return Address Stack)：以栈的形式记录CALL指令的下一条指令地址\n适用指令：间接跳转Return指令 用途：预测Return指令的跳转地址(因为函数调用和返回一定满足栈的性质)，上表中加粗表示的即为RAS对函数调用密集型测试点的重大作用 RAS满时，对RAS使用循环更新，即再从底向上开始更新，可以尽可能保证预测准确性 分支预测器不会被flush\n2.2.2.2 TLB 考虑到TLB的全相连结构，它在被查询时硬件复杂度较高。为此，我们设计了同步读取的TLB逻辑，无论是前端还是后端的地址翻译，我们均会在第一拍发送虚地址，进行TLB表项的查询，同时进行mmu的判断，是否为直接地址翻译或直接地址映射，若为TLB页表映射，则锁存命中信息供下一拍使用；在下一拍同时得到例外有关信息。这样的设计均摊了查询TLB表项的复杂度，有效的提高了频率。\n2.2.3 预译码 PreDecode 为进一步降低分支预测失败造成的影响，我们创造性的在解码之前加入了预译码级，在这一级中，我们在力所能及的程度下对分支结果进行最迅速的检查，并且在发现错误的第一时间通知前端重新取指。\n在这一级中会处理以下情况：\n必定跳转指令但预测不跳转：大概率是初次执行，更正预测结果并且更新分支预测器 非跳转指令但预测跳转：不可能产生这种情况，因为仅当BTB命中才会产生预测，非跳转指令BTB不可能命中 如若跳转地址错误，更正预测结果并且更新分支预测器 2.2.3.1 指令缓冲 Instruction Buffer (IB) 在预译码级与译码级之间，我们使用自己设计的FIFO，实现了一个指令缓冲，用于解耦取指级与译码级。该缓冲让取指效率最大化，无论后端是否阻塞都不会浪费前端的取指资源，做到了效率的最大利用；前端只需专注取指并填充至IB，而后端只需专注于从IB中取出指令并执行，极大地提高了处理器的执行效率。\n同时，为了保证后续流水线资源的最大利用率，取指前端保证IB中的信息均为有效指令，排除任何气泡指令向下一级传输。\n2.1.4 译码 Decode 本级用于译码，我们通过chisel语言的特性，利用BitPat生成树形译码元件进行译码，并输出指令所需信息(例如功能模块名和具体功能)，做到了代码上的清晰明了。\n同时，我们会在这一级对于指令进行中断的标记，保证了CPU资源的利用率。\n2.2.5 重命名 Rename 重命名级是CPU乱序架构当中至关重要的一环。为了消除CPU后端乱序写回带来的写后写、读后写的相关性问题，保证乱序执行的正确性，在重命名级当中，我们将对于逻辑寄存器areg进行物理寄存器preg的分配。\n同时，为了保证指令乱序执行后，能够顺序地对于处理器状态进行更新，我们还需要对于重排序缓存ROB进行表项空间的申请，获得本级指令对应的ROB编号，从而保证最终在后端提交时能够通过编号实现顺序的提交。\n具体实现时，当RAT分配物理寄存器时，将会从空闲寄存器表freelist当中取最多两个空闲寄存器，作为原逻辑寄存器areg对应的物理寄存器preg。同时，这一级会向发射级发送占用寄存器的请求，以此阻塞发射队列当中的相关指令，从而保证了后端指令唤醒顺序的正确性。在申请ROB空间的时候，ROB通过其fifo指针分配两条指令对应的ROB编号，并且会保存指令对应的信息。\n至此，指令开始占用寄存器映射表信息、ROB表项、物理寄存器资源，可以认为指令从本级开始即将进入后端执行的流程当中。\n2.3 后端设计 后端分为六个流水级，分别为分发（Dispatch）、发射（Issue）、读寄存器（ReadReg）、执行（Execute）、写回（WriteBack）、提交（Commit）。其中，执行级又根据流水线功能的不同，细分为1~3个流水级。算术流水线只有一级执行级，而乘除和访存有三级执行级。\n从发射级开始，后端分为四条独立的流水线，分别是2条算术执行流水线，1条乘除法执行流水线，1条访存执行流水线。\n需要注意的是，特权指令放在乘除法。为了保证csr写指令的正确性，在重排序缓存提交指令的时候，才写csr寄存器并冲刷整条流水线。\n2.3.1 分发 Dispatch 本级会根据指令的类型，分发指令到各个流水线发射缓存当中。考虑到后端很有可能处于访存密集或算术密集状态，某一流水线可能被完全占满，因此我们的分发级允许只分发一条，而保留第二条指令到握手成功再进行分发。这样的分发逻辑能够使得满流水线时也能执行一定数量的其他流水线指令，从而提高了CPU的执行效率。\n2.3.2 发射 Issue 这里定义了四个发射队列，对于单个发射队列，每个周期最多接收、发射一条指令。\n不同流水线的发射情况如下：\n运算流水线，我们已经通过寄存器重命名保证了乱序写回的正确性，因此乱序发射即可。 乘除流水线，由于我们将特权指令分配在了本流水线，因此本流水线需要保证顺序发射。 访存流水线，由于数据缓存只有一个，且需要维护访存数据的一致性，所以必须保证顺序发射。 对于乱序发射的队列，我们使用了压缩队列实现。发射时将检查队列内所有指令的寄存器占用状态，若发现相关寄存器均已被唤醒则可以发射。关于寄存器占用状态的维护，我们会在发出唤醒信号的下一拍更新状态，并额外维护从写缓存中回传的uncached load的对应占用状态，防止冲刷导致相关寄存器的占用状态被解除。\n对于乱序发射的队列，会按照指令从旧到新的优先级进行发射，这是因为较旧的指令更有可能拥有较多的相关指令，一次发射能够唤醒更多的指令。对于顺序发射的队列，我们每个周期只会对队列头部的指令进行寄存器占用情况的检查，只会发射队列中的最旧指令，从而保证了这些需要顺序执行的指令的一致性。\n2.3.3 读寄存器 ReadReg 这一级流水线在每条流水线当中都独立存在，负责从物理寄存器当中读出源操作数对应的数值。寄存器堆对于每一条流水线都分配了一个读接口。同时这一级也会接收执行级和写回级前递的信息，用于实现指令的背靠背执行的前递信号传递。 发生前递时，我们会对于前递的寄存器号进行比较。于我们比较的是物理寄存器地址，必定保证写相关寄存器的指令最多只会存在一个，因此可以使用独热码的判命中逻辑，这节约了一定的逻辑复杂度。\n如果是算术流水线的读寄存器阶段，还会进行相关指令的唤醒。在本级进行唤醒，能够保证下一拍相关指令进入readreg级，从而直接从算术执行级当中获得前递的数据，从而保证了指令的背靠背执行。\n2.3.4 算术流水线 Arithmetic 算术流水线是CPU执行过程当中，访问最频繁的流水线。在算术流水线当中，我们的CPU会进行算术和分支指令的执行过程。考虑到这两类指令需要的元器件数目并不多，可以分配多条算术流水线用于这类指令的执行。\n由于我们的前端取指深度为2，后端也应该分配两条算术流水线，以保证算术密集型指令集当中，CPU后端理论能够持续维持双发射的算术指令提交行为。我们在算术指令密集的bitcount等测试集当中，获得了1.2以上的IPC，这证明了我们运算流水线双发+背靠背执行逻辑的可靠性。\n2.3.5 乘除流水线 Muldiv 用于乘除指令与特权指令的执行，分为三级。拆分成多个流水级的主要原因是需要实现乘法运算的流水化。\n对于乘法运算，我们使用xilinx ip搭载了一个三级流水的乘法器，实现了乘法运算的流水化，这使得我们在执行大量乘法运算的时候，能够实现完全的流水化提交过程，优化了CPU的执行效率。\n对于除法运算，我们使用xilinx ip实现了除法器，并在乘除流水线的第一级中进行阻塞执行，考虑到除法指令在实际程序中的占比较低，阻塞式的执行逻辑并不会对于我们的执行效率产生过大影响。\n对于特权指令，我们会将写指令放入特权缓存PrivBuffer当中，并阻塞后续所有特权指令，直到后端ROB进行提交的时候，才使得相关的非普通寄存器更改生效。这样的提交逻辑能够有效保证特权指令配置的一致性，防止特权指令提早对于处理器状态进行更改，并做到了较低的逻辑复杂度，能够更好的优化特权指令提交的复杂度。\n2.3.6 访存流水线 Memory 访存流水线是后端流水线当中最重要的一条，也是设计难度最高的一条。\n对于访存指令，某些访存指令会对处理器状态进行修改，因为其对处理器状态产生的影响不好撤销，所以当执行这些指令时，使用Store Buffer(写缓存)对这种类型的访存指令进行暂存，只有当提交时，才会回传至访存流水线真正执行。\n考虑到硬件复杂度和频率要求，我们设计了多级流水线以提高频率。\n2.3.6.1 Mem0 这一级用于计算访存的虚地址以及TLB的相关信息。\n按照2.2.2.2 TLB提到的同步读取的TLB设计，我们会在本级计算vaddr，并发送至TLB，由TLB进行翻译。\n若是直接地址翻译或直接地址映射，直接将得到的物理地址传递给Mem1级 若是映射地址翻译，给TLB表项发地址，得到命中信息并传递给Mem1级 2.3.6.2 Mem1 在这一级中会选择接受是已提交的访存指令还是Mem0传递而来的指令。在仲裁两条指令的时候，我们会优先选择已提交的访存指令进行执行，从而防止了因为缓存满而导致的阻塞。\n除此之外，Mem1级还会对于TLB相关信息进行维护，逻辑如下：\n在此级中把命中信息发送至TLB，读出命中表项，翻译出paddr；并且判断是否存在TLB相关例外 vaddr发送至D-Cache，索引D-Cache的Tag-sram和Data-sram 2.3.6.3 Mem2 将paddr发送至D-Cache，判定是否命中，若不命中则进入阻塞状态，并与主存利用axi接口交互取出Cache缺失行，若命中则执行可执行的访存指令 可执行访存指令：cached load指令，回滚访存指令 不可执行访存指令：uncached load指令、store指令、原子访存指令和cacop指令。对于这些指令，将其push进Store Buffer 对于cached load指令，我们将从D-Cache中读出的数据传递下去，在写回级进行前递判断，进而降低mem2的硬件复杂度 2.3.6.4 写缓存 Store Buffer 在乱序处理器当中，为了保证处于推测态的访存指令不会对外部状态进行更改，我们使用了写缓存Store Buffer来维护。\n当接收到ROB的提交后，会将写缓存内的信息通过Mem1级重新回流到访存流水线当中。 由于Mem1需要同时接受来自Mem0的数据和来自写缓存的数据，当Mem0向Mem1发送数据时，还会与写缓存发送的数据进行竞争，优先让写缓存内数据进行访存。 当发生flush时，Store Buffer直接清空即可 2.3.6.5 数据(指令)缓存 Cache 每路的组织形式如下，在我们的设计中index = 8。\nLine $0$ bank 0 bank 1 bank 2 bank 3 valid dirty Tag 32 b 32 b 32 b 32 b 1 b 1 b (32 - index) b \u0026hellip;\nLine $2^{index} - 1$ bank 0 bank 1 bank 2 bank 3 valid dirty Tag 32 b 32 b 32 b 32 b 1 b 1 b (32 - index) b I-Cache和D-Cache采取了同样的组织形式，只是I-Cache取消了dirty位；bank在I-Cache代表了指令，在D-Cache中代表了数据。\n为了降低访存复杂度，我们着重设计了访存的状态机，为了获得优秀的硬件复杂度将复杂流程拆分。\n具体状态分为：idle(闲置状态，判断命中)、uncached_read、uncached_write、check_dirty、writeback、replace_line，其中I-Cache无关于写操作的状态\n2.3.7 写回 WriteBack 这一级用于写物理寄存器，更新rob当中对应的提交信息，并更新发射队列当中的寄存器占用状态。\n对于访存流水线，在我们原先的设计当中，推测唤醒会导致大量控制信号串行，从而导致关键路径产生、频率下降。因此，为了时序考虑，直到这一级才会对与访存指令相关的指令进行唤醒。在这一逻辑下，我们的IPC从原先的0.84降至0.78，但我们的频率由65MHz升至了83MHz，相较之下提升幅度达到了18%，因此我们取消了推测唤醒的设计，改为写回级唤醒。\n2.3.8 提交 Commit 这一级用于进行最终的提交，解除对于CPU资源的占用，并解除寄存器的推测态。\n解除对于上一个物理寄存器的占用（opreg），并将opreg对应的寄存器编号插入到空闲寄存器列表freelist 更新aRAT的映射关系，aRAT当中存储的是由已经提交的指令构成的、不涉及推测态指令的寄存器映射表 对于包括分支、访存、特权在内的部分非算术指令，由于分支预测器更新限制、写缓存入队限制等原因，我们在检测到这些指令的时候，不会进行双指令的提交。假如检测到分支预测失败或例外，还会向冲刷控制器发出冲刷请求。 当发生流水线清空的时候，首先向冲刷控制器发出请求。冲刷控制器会延迟一拍后，对于各个流水线及功能部件发出冲刷信号，并令重命名相关部件进行状态恢复。具体而言，状态恢复时，会将aRAT赋值给cRAT，清空rob当中的所有表项，并将freelist的尾指针置为头指针位置。 在提交级，我们通过ROB重排序缓存，成功实现了乱序执行结果的顺序写回过程，保证了乱序CPU在执行上的一致性，通过乱序架构的设计，我们的CPU达到了良好的性能表现。\n3. 参考文献 [1] J. Ye, and L. Xi, PUA-MIPS, https://github.com/Clo91eaf/PUA-MIPS, 2023\n[2] Z. Ma, LA32R-pipeline-scala, https://github.com/MaZirui2001/LA32R-pipeline-scala, 2023\n[3] H. Gao, and M. Liu, NOP-Core, https://github.com/NOP-Processor/NOP-Core, 2023\n[4] Y. Zhou, S. Chen, X. Liu and J. Chen, Nontrivial-mips,https://github.com/trivialmips/nontrivial-mips, 2019\n[5] W. Wang, and J. Xing, CPU Design and Practice, Beijing: China Machine Press, 2021\n[6] Y. Yao, SuperScalar RISC Processor Design, Beijing: Tsinghua University Press, 2014\n","date":"2024-08-14T00:00:00Z","image":"https://crpboy.github.io/p/nscscc-2024-report/cover_hu6374802966040036931.png","permalink":"https://crpboy.github.io/p/nscscc-2024-report/","title":"NSCSCC2024决赛汇报文档"},{"content":"原题链接\n考虑用主席树+倍增+dfn维护\n首先，当$p\\in[l,r]$，或者p的祖先和子树内均有点$x\\in[l,r]$的时候，答案必为0。\n除去以上情况，这些点要么都在我的祖先的子树（且p不在这些子树中）内，要么都在p的子树内\n祖先情况 需要找到我的一个祖先点x满足： $[l,r]$的点都不在点x的子树内\nx是满足第一种情况的最高点\n考虑用倍增维护，主席树查询$[l,r]$上的和即可\n其中，主席树对编号开点，以dfn作为插入的先后顺序\n或者需要找到一个不处于p子树内的点x满足： x为所有$y\\in[l,r]$的lca\n点p不在x的子树内\n直接倍增判断是否符合答案即可，最终答案就是x到p的路径长度\n对于子树情况 需要找到p的子树内的一个节点x满足： $[l,r]$的点都在点x的子树内\nx是满足第一种情况的最低点\n怎样找到x？随便挑一个点$y\\in[l,r]$，我要的答案点x一定在它到$p$的路径上\n那么直接倍增跳就好了\n时间复杂度$O(n \\log^2 n)$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; #define dd ch=getchar() int read() { char dd;int x=0;bool f=false; while(!isdigit(ch))f|=ch==\u0026#39;-\u0026#39;,dd; while(isdigit(ch))x=x*10+ch-48,dd; return f?-x:x; } #undef dd void write(int x) { if(x\u0026lt;0)x=-x,putchar(\u0026#39;-\u0026#39;); if(x\u0026gt;9)write(x/10); putchar(x%10+48); } #define writesp(x) (write(x),putchar(\u0026#39; \u0026#39;)) #define writeln(x) (write(x),putchar(\u0026#39;\\n\u0026#39;)) const int N=2e5+5; int n,q; struct node { int v,w,nxt; }a[N\u0026lt;\u0026lt;1]; int head[N],cnt=0; void add(int u,int v,int w) { a[++cnt].v=v; a[cnt].w=w; a[cnt].nxt=head[u]; head[u]=cnt; } int tot=0; int rt[N],t[N*50],ls[N*50],rs[N*50],fa[N][25]; void push_up(int p) { t[p]=0; if(ls[p])t[p]+=t[ls[p]]; if(rs[p])t[p]+=t[rs[p]]; } int modify(int pre,int l,int r,int pos) { int p=++tot; ls[p]=ls[pre],rs[p]=rs[pre]; if(l==r){t[p]=1;return p;} int mid=(l+r)\u0026gt;\u0026gt;1; if(pos\u0026lt;=mid)ls[p]=modify(ls[pre],l,mid,pos); else rs[p]=modify(rs[pre],mid+1,r,pos); push_up(p); return p; } int query(int p,int l,int r,int L,int R) { if(!p)return 0; if(L\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=R)return t[p]; int mid=(l+r)\u0026gt;\u0026gt;1,ans=0; if(L\u0026lt;=mid)ans+=query(ls[p],l,mid,L,R); if(mid\u0026lt;R)ans+=query(rs[p],mid+1,r,L,R); return ans; } int size[N],dep[N],deep[N],dfn[N],num=0; void dfs(int u) { size[u]=1; dfn[u]=++num; rt[num]=modify(rt[num-1],1,n,u); for(int i=1;i\u0026lt;=20;i++) fa[u][i]=fa[fa[u][i-1]][i-1]; for(int i=head[u];i;i=a[i].nxt) { int v=a[i].v,w=a[i].w; if(v==fa[u][0])continue; dep[v]=dep[u]+w;deep[v]=deep[u]+1; fa[v][0]=u; dfs(v); size[u]+=size[v]; } } int getres(int x,int l,int r) { return query(rt[dfn[x]+size[x]-1],1,n,l,r)-query(rt[dfn[x]-1],1,n,l,r); } int lca(int x,int y) { if(deep[x]\u0026lt;deep[y])swap(x,y); for(int i=20;i\u0026gt;=0;i--) if(deep[fa[x][i]]\u0026gt;=deep[y]) x=fa[x][i]; if(x==y)return x; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]!=fa[y][i]) x=fa[x][i],y=fa[y][i]; return fa[x][0]; } int query1(int x,int l,int r) { int o=x; if(getres(o,l,r))return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;!getres(fa[x][i],l,r)) x=fa[x][i]; x=fa[x][0]; if(!x)return 0; return dep[o]-dep[x]; } int query2(int x,int l,int r) { int o=x;x=l; if(getres(o,l,r)!=r-l+1)return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;getres(fa[x][i],l,r)!=r-l+1) x=fa[x][i]; if(getres(x,l,r)!=r-l+1)x=fa[x][0]; if(!x)return 0; return dep[x]-dep[o]; } int query3(int x,int l,int r) { int o=x;x=l; if(getres(o,l,r))return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;getres(fa[x][i],l,r)!=r-l+1) x=fa[x][i]; if(getres(x,l,r)!=r-l+1)x=fa[x][0]; if(!x||getres(x,o,o)==1)return 0; return dep[o]+dep[x]-dep[lca(x,o)]*2; } int main() { //\tfreopen(\u0026#34;6071.in\u0026#34;,\u0026#34;r\u0026#34;,stdin); //\tfreopen(\u0026#34;6071.out\u0026#34;,\u0026#34;w\u0026#34;,stdout); n=read(),q=read(); for(int i=1,u,v,w;i\u0026lt;n;i++) u=read(),v=read(),w=read(),add(u,v,w),add(v,u,w); dfs(1); int lasans=0; while(q--) { int p=read()^lasans,l=read()^lasans,r=read()^lasans; writeln(lasans=max(query1(p,l,r),max(query2(p,l,r),query3(p,l,r)))); } return 0; } ","date":"2022-11-16T00:00:00Z","image":"https://crpboy.github.io/p/luogu-p6071-solution/cover_hu478156444678039639.png","permalink":"https://crpboy.github.io/p/luogu-p6071-solution/","title":"洛谷P6071『MdOI R1』Treequery"}]