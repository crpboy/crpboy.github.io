[{"content":"项目链接\n概况 本次NSCSCC比赛，我们NoAXI团队取得了二等奖，使用乱序双发射实现CPU，IPC为0.78，频率为83MHz。\n比较遗憾的是，我们没有在规定的时间内成功启动Linux系统，导致我们最终的系统成绩分偏低。所幸答辩成绩还算过关，最终顺利拿到了二等奖。\n心路历程 我们团队一开始都是打个人赛的，直到6月中旬才决定转成团队赛。所以我必须得介绍一下我们团队在组队之前的神奇经历。\n我在3月底开始接触的龙芯杯，先花了半个月时间，配置环境并且学习chisel的语法。大概到了4月中旬的时候，我写出了一个最朴素的顺序五级流水。此后就在此基础上不断完善，一直到6月份写到了Cache和TLB的开发。当时并不知道个人赛会有这么多简化，直到6月份自己做到了TLB才发现，已经走的太远了。我们的AXI状态机和TLB都没法用在个人赛当中，只能去团队赛了。\n于是果断转团队赛，跟涛哥一起组了NoAXI队。从6月中旬开始，我花了一周时间啃完了《超标量》并设计了乱序的基础结构。考试周期间比较忙，一直到7月份才有空写代码。我们团队从零开始，完全抛弃了原有的5级流水线设计，重写了一份乱序的代码，我主要负责的就是乱序架构相关的内容。大概到了7月中旬，终于成功地跑通了仿真。\n但是当时我们因为DCache中SRAM实现上的问题，出现了仿真通过，上板未通过的情况。我们前后花了一周的时间去debug，在vivado里面拉debug信号进行调试，一跑就是两个小时，可以说是非常痛苦。\n调完bug之后，我们的初赛也差不多相当于准备完毕了。此后我跑去起SoC，涛哥则准备启动linux。原本我设想的是起一个往年一等奖级别的定制化SoC，能够启动大部分的外设的，但因为驱动相关的原因，我最终没有成功启动以太网口，只能使用官方提供的SoC。我们最后的Linux也因为分支预测一致性问题而启动失败。可以说决赛相关的工作我们几乎全军覆没。\n最后两天我们连续熬了两个通宵，改了起Linux过程中的五六个bug，但最终差临门一脚，没有成功。算是留下了挺多的遗憾。\n启示，反思和总结 我们最终的设计版本其实很早就设计完毕了，但最终我们在访存相关的维护上面花了非常多的时间，尤其是访存的唤醒信号时延和一致性维护问题。我也希望，读到这篇文章的人在设计乱序CPU后端访存部件的时候，务必注意这些问题。\n其实很多东西，不去实操是绝对不会懂得的。永远不要想当然，永远不要去优化自己猜想的路径，而应该根据数据进行优化。我在做访存之前，甚至想象过访存是一个与算术流水线差不多复杂度的东西，这使得我们在设计推测唤醒和优化时序的时候付出了惨重的代价。我们的唤醒也做得有点问题，我把一个串行逻辑写了进去，导致我最终无法把访存的推测唤醒加到里面去。这些问题很大程度上都是我想当然导致的。\n说实话，我们这次比赛全程都在和时间赛跑，DDL一个接着一个地来，把我压的喘不过气来。6月中旬开始做乱序，8月中旬就要决赛提交，2个月的时间对于我们来说实在是太短了。我不止一次地想，如果再多给我们一个星期，说不定就能有新的转机了呢。但不论如何，我们既然做了乱序，就必须克服乱序带来的诸多设计难题。赶不上DDL也只能说是情有可原。\n不过设计乱序的过程也的确让我学到了大量实操经验，我能明显感觉到自己在开发上更加熟练了。赛后我和涛哥讨论，发现其实我们的CPU里面存在大量可优化的地方。还是明年再来一场，争取不留遗憾吧。\n","date":"2024-09-03T00:00:00Z","image":"https://crpboy.github.io/p/nscscc-2024-summary/cover_hu17938661769826131365.jpg","permalink":"https://crpboy.github.io/p/nscscc-2024-summary/","title":"NSCSCC2024 赛后总结"},{"content":"背景 龙芯杯之后，我觉得有必要写一个超标量处理器相关的总结文章。在跟着《超标量处理器设计》学习乱序的过程当中，我遇到了大量书上没有涉及到的细节问题。这一方面是因为我个人能力有限，忽略掉了原书的一些细节描述，导致理解上的偏差；另一方面，对于初学者而言，确实存在很多基础问题，一旦没搞懂就会导致巨大的理解成本。所以就有了这篇文章。\n前置知识 请保证在你阅读本文章之前，已经掌握以下知识点：\n对于基础的单发射五级流水线CPU有一定的了解 能够实现一个拥有算术、分支、访存功能的简易CPU 如果不够了解相关内容，可以先去学习《CPU设计实战》再来阅读本文章。\n乱序设计概述 定义 我们不妨先看看《超标量》是怎么说的。\n超标量处理器能够在一个周期内执行多条指令，这样可以缩短一个程序的执行时间，指令在处理器中可以按照程序中指定的顺序来执行，也可以不遵循这个顺序，只要指令的源操作数都准备好了，它就可以被执行，这种方式就称为乱序执行(out-of-order)。\n注意这个描述：“只要指令的源操作数都准备好了，它就可以被执行”。对于一个乱序执行过程而言，指令的处理可以大致分为 等待源操作数 $\\to$ 乱序执行 $\\to$ 顺序提交 三个过程。\n乱序不代表完全混乱，乱序CPU也需要遵守冯诺依曼模型规定的顺序执行规则。因此，它至少得在执行前保证能够读取到正确的源操作数值，并且保证这条指令的执行结果必定会生效，不会因为分支失败等原因被冲刷。\n乱序的优势 首先明确一个概念：相关性。令指令1为C=A+B，指令2为D=C+E，则D值的求出依赖于C值，我们称指令1与指令2相关。这就是指令之间的相关性。在CPU的执行过程中存在着大量的相关指令，他们之间的依赖关系是实现程序并行执行的最大阻碍。\n在编译过程当中，数据会根据依赖关系，构成一张有向无环图DAG。这张DAG上，每一条链都是由若干具有相关性的指令组成的。而乱序能够在不存在相关性的两条DAG链上，各自独立地往下执行，直到碰到需要阻塞的指令为止。\n对于顺序CPU而言，一旦某条多周期指令需要阻塞流水线，则后面所有的指令，不论是否与这条指令相关，都会被阻塞住。但对于乱序CPU而言，这只是DAG图上的某条链产生了阻塞，不影响其他链的执行进程，所以所有不具备相关性的指令，都仍然可以正常地在阻塞期间被执行。这就使得乱序架构在多周期/单周期指令混杂的场景中能够最大程度地发挥指令并行的能力。\n乱序CPU的基础结构 未完待续\u0026hellip;\n","date":"2024-09-02T00:00:00Z","image":"https://crpboy.github.io/p/out-of-order-tutorial/cover_hu17113026730877005545.png","permalink":"https://crpboy.github.io/p/out-of-order-tutorial/","title":"乱序CPU入门指南"},{"content":"项目链接\n1. 概述 1.1 项目简介 本项目是第八届\u0026quot;龙芯杯\u0026quot;全国大学生计算机系统能力培养大赛（NSCSCC 2024）的参赛作品。\n本项目为基于龙芯架构32位精简版指令集(LA32R)，开发的一款乱序多发射的CPU。项目基于Tomasulo动态调度算法，使用ROB重排序缓存，实现了一个乱序执行、后端四发射的CPU，最深级数到达了13。此外，我们还实现了分支预测、Cache缓存等诸多特性。我们在官方提供的性能测试框架当中，达到了0.78的IPC，I/DCache的命中率均达到了**98.8%**以上，使得CPU取得了良好的性能表现。\n1.2 处理器总体参数 我们非常关注处理器执行指令的效率，因此，下面将给出我们CPU在执行官方提供的性能测试框架时的相关参数概览。\n从下表可以看到，我们的I/D-Cache达到了98%以上的高命中率，优秀的访存维护逻辑使得我们的CPU在访存密集型测试集当中保持了良好的IPC。同时我们的分支命中成功率也达到了91.4%，这使得我们的CPU能够尽可能地避免分支预测失败带来的大量气泡，为我们加深流水级、实现后端乱序执行打下了良好的基础。\n项目 参数 IPC 0.78 频率 83hz 分支预测成功率 91.4% I-Cache命中率 99.6% D-Cache命中率 98.8% 流水级数 13 1.3 实现功能 我们的指令集支持了龙芯架构32位精简版中除了浮点指令以外的所有指令，并支持了指令集中全部CSR寄存器的维护，实现了丰富的指令功能。\n算数类指令：ADD.W, SUB.W, ADDI.W, LU12I.W, SLT[U], SLT[U]I, PCADDU12I, AND, OR, NOR, XOR, ANDI, ORI, XORI, MUL.W, MULH.W[U], DIV.W[U], MOD.W[U], SLL.W, SRL.W, SRA.W, SLLI.W, SRLI.W, SRAI.W 跳转指令：BEQ, BNE, BLT[U], BGE[U], B, BL, JIRL 访存指令：LD.B, LD.H, LD.W, LD.BU, LD.HU, ST.B, ST.H, ST.W,LL,SC CSR相关指令：CSRRD, CSRWR, CSRXCHG Cache相关指令：CACOP TLB相关指令：TLBSRCH, TLBRD, TLBWR, TLBFILL, INVTLB 栅障指令：IBAR,DBAR 其他杂项指令：RDCNTVL.W, RDCNTVH.W, RDCNTID, SYSCALL, BREAK, ERTN 2. 处理器微架构设计 2.1 整体介绍 NoAXI处理器采取前后端设计，前端共5个流水级，后端共6个流水级，共11个流水级，最深级数为13。\n前端五个流水级，分别为 预取指、取指、预译码、译码、重命名。\n后端分为六个流水级，分别为 分发、发射、读寄存器、执行、写回、提交。\n其中执行级分为并行的四条流水线，分别为：算术流水线0、算术流水线1、乘除流水线、访存流水线。\n前端采取顺序双发射设计，取指宽度为2，每个周期可以向后端最多传输2条指令。\n后端采取乱序四发射设计，流水线条数为4，每个周期可以进行最多2条指令的提交。\n2.2 前端设计 前端分为 预取指（PreFetch）、取指（Fetch）、预译码（PreDecode）、译码（Decode）、重命名（Rename） 共五级。\n其中，预译码级与译码级之间，使用了一个指令缓冲（Instruction Buffer）进行解耦。\n2.2.1 预取指 PreFetch 在这一级中进行pc的更新，并且将虚地址发送给TLB。\npc发送至TLB，TLB进行翻译 若是直接地址翻译或直接地址映射，直接将得到的物理地址传递给Fetch级 若是映射地址翻译，给TLB表项发地址，得到命中信息并传递给Fetch级 pc发送至I-Cache，基于VIPT原理，给I-Cache索引 pc发送至BPU，进行分支预测(发送按双字对齐的两个pc进行预测，如果第二个pc不满足双字对齐则不预测) pc发送至BTB读取信息 pc发送至BHT得到跳转历史，寄存器锁存供下一拍使用 根据情况更新pc (最高优先级)后端传来的跳转请求：可能是例外中断造成的跳转，也可能是特权指令需要冲刷流水线，也可能是分支预测失败的重新取指 (第二优先级)分支预测传来的跳转请求 (第三优先级)更新pc为按双字对齐的下一个pc，例如 1c001000 $\\rightarrow$ 1c001008，1c00110c $\\rightarrow$ 1c001110 2.2.2 取指 Fetch 为降低硬件复杂度，我们设计了独特的取指方式，选择双字对齐方式的双指令取指。相较于四指令取指，这样的取指方式降低了因分支预测造成的标记无效指令的硬件开销，并且，效率也不会得到大幅降低，因为我们的I-Cache一行存四个指令，大部分正常取指的情况下，两次取指中的第二次是必定命中I-Cache的，保证了前端取指的高效。\n在此级中把命中信息发送至TLB，读出命中表项，翻译出paddr；并且判断是否存在TLB相关例外 将得到的paddr发送至I-Cache，判定是否命中，若不命中则进入阻塞状态，并与主存利用axi接口交互取出Cache缺失行 取出两条指令，并且保证pc是按双字对齐的，若第二条指令pc未满足条件则会标记为无效 得到分支预测的结果 利用上一拍得到的BTB信息和BHT中读取到的BHR，得到预测方向和跳转结果 若预测跳转，清刷prefetch并对其发出跳转请求 2.2.2.1 分支预测器 BPU 在乱序处理器当中，因为流水级数深，分支预测失败代价过大。因此，分支预测器很大程度上决定着cpu的IPC。\n为降低硬件复杂度，我们同样设计了两级BPU，将整个预测过程分为了两拍完成。我们使用了基于局部历史的饱和计数器分支预测结合BTB和RAS对多种分支场景进行了有效的分支预测，下表是性能测试中十个测试点的具体成绩。\n测试点编号 测试点名称 无RAS分支预测成功率 分支预测成功率 1 bitcount 80.510 % 94.509 % 2 bubble_sort / 84.935 % 3 coremark / 88.955 % 4 crc32 90.100 % 96.367 % 5 dhrystone / 95.331 % 6 quick_sort / 74.780 % 7 select_sort / 93.456 % 8 sha / 98.284 % 9 stream_copy / 95.924 % 10 stringsearch / 93.666 % BHT(Branch History Table)：保存跳转指令的跳转局部历史，在跳转指令提交时更新\nPHT(Pattern History Table)：记录跳转历史对应的饱和计数器值，对应跳转的方向趋势，用于预测跳转方向\nBTB(Branch Target Buffer)：记录pc对应的跳转地址，兼顾判断跳转类型(CALL,Return,其他)的职责\n适用指令：条件跳转类和CALL型指令 用途：记录指令的跳转类型，是否为跳转指令(valid位)，跳转地址 仅当BTB命中时才可能发生分支预测 表项组织形式如下： Valid Tag Target Br_type 1 b (32 - index) b 32 b 2 b RAS(Return Address Stack)：以栈的形式记录CALL指令的下一条指令地址\n适用指令：间接跳转Return指令 用途：预测Return指令的跳转地址(因为函数调用和返回一定满足栈的性质)，上表中加粗表示的即为RAS对函数调用密集型测试点的重大作用 RAS满时，对RAS使用循环更新，即再从底向上开始更新，可以尽可能保证预测准确性 分支预测器不会被flush\n2.2.2.2 TLB 考虑到TLB的全相连结构，它在被查询时硬件复杂度较高。为此，我们设计了同步读取的TLB逻辑，无论是前端还是后端的地址翻译，我们均会在第一拍发送虚地址，进行TLB表项的查询，同时进行mmu的判断，是否为直接地址翻译或直接地址映射，若为TLB页表映射，则锁存命中信息供下一拍使用；在下一拍同时得到例外有关信息。这样的设计均摊了查询TLB表项的复杂度，有效的提高了频率。\n2.2.3 预译码 PreDecode 为进一步降低分支预测失败造成的影响，我们创造性的在解码之前加入了预译码级，在这一级中，我们在力所能及的程度下对分支结果进行最迅速的检查，并且在发现错误的第一时间通知前端重新取指。\n在这一级中会处理以下情况：\n必定跳转指令但预测不跳转：大概率是初次执行，更正预测结果并且更新分支预测器 非跳转指令但预测跳转：不可能产生这种情况，因为仅当BTB命中才会产生预测，非跳转指令BTB不可能命中 如若跳转地址错误，更正预测结果并且更新分支预测器 2.2.3.1 指令缓冲 Instruction Buffer (IB) 在预译码级与译码级之间，我们使用自己设计的FIFO，实现了一个指令缓冲，用于解耦取指级与译码级。该缓冲让取指效率最大化，无论后端是否阻塞都不会浪费前端的取指资源，做到了效率的最大利用；前端只需专注取指并填充至IB，而后端只需专注于从IB中取出指令并执行，极大地提高了处理器的执行效率。\n同时，为了保证后续流水线资源的最大利用率，取指前端保证IB中的信息均为有效指令，排除任何气泡指令向下一级传输。\n2.1.4 译码 Decode 本级用于译码，我们通过chisel语言的特性，利用BitPat生成树形译码元件进行译码，并输出指令所需信息(例如功能模块名和具体功能)，做到了代码上的清晰明了。\n同时，我们会在这一级对于指令进行中断的标记，保证了CPU资源的利用率。\n2.2.5 重命名 Rename 重命名级是CPU乱序架构当中至关重要的一环。为了消除CPU后端乱序写回带来的写后写、读后写的相关性问题，保证乱序执行的正确性，在重命名级当中，我们将对于逻辑寄存器areg进行物理寄存器preg的分配。\n同时，为了保证指令乱序执行后，能够顺序地对于处理器状态进行更新，我们还需要对于重排序缓存ROB进行表项空间的申请，获得本级指令对应的ROB编号，从而保证最终在后端提交时能够通过编号实现顺序的提交。\n具体实现时，当RAT分配物理寄存器时，将会从空闲寄存器表freelist当中取最多两个空闲寄存器，作为原逻辑寄存器areg对应的物理寄存器preg。同时，这一级会向发射级发送占用寄存器的请求，以此阻塞发射队列当中的相关指令，从而保证了后端指令唤醒顺序的正确性。在申请ROB空间的时候，ROB通过其fifo指针分配两条指令对应的ROB编号，并且会保存指令对应的信息。\n至此，指令开始占用寄存器映射表信息、ROB表项、物理寄存器资源，可以认为指令从本级开始即将进入后端执行的流程当中。\n2.3 后端设计 后端分为六个流水级，分别为分发（Dispatch）、发射（Issue）、读寄存器（ReadReg）、执行（Execute）、写回（WriteBack）、提交（Commit）。其中，执行级又根据流水线功能的不同，细分为1~3个流水级。算术流水线只有一级执行级，而乘除和访存有三级执行级。\n从发射级开始，后端分为四条独立的流水线，分别是2条算术执行流水线，1条乘除法执行流水线，1条访存执行流水线。\n需要注意的是，特权指令放在乘除法。为了保证csr写指令的正确性，在重排序缓存提交指令的时候，才写csr寄存器并冲刷整条流水线。\n2.3.1 分发 Dispatch 本级会根据指令的类型，分发指令到各个流水线发射缓存当中。考虑到后端很有可能处于访存密集或算术密集状态，某一流水线可能被完全占满，因此我们的分发级允许只分发一条，而保留第二条指令到握手成功再进行分发。这样的分发逻辑能够使得满流水线时也能执行一定数量的其他流水线指令，从而提高了CPU的执行效率。\n2.3.2 发射 Issue 这里定义了四个发射队列，对于单个发射队列，每个周期最多接收、发射一条指令。\n不同流水线的发射情况如下：\n运算流水线，我们已经通过寄存器重命名保证了乱序写回的正确性，因此乱序发射即可。 乘除流水线，由于我们将特权指令分配在了本流水线，因此本流水线需要保证顺序发射。 访存流水线，由于数据缓存只有一个，且需要维护访存数据的一致性，所以必须保证顺序发射。 对于乱序发射的队列，我们使用了压缩队列实现。发射时将检查队列内所有指令的寄存器占用状态，若发现相关寄存器均已被唤醒则可以发射。关于寄存器占用状态的维护，我们会在发出唤醒信号的下一拍更新状态，并额外维护从写缓存中回传的uncached load的对应占用状态，防止冲刷导致相关寄存器的占用状态被解除。\n对于乱序发射的队列，会按照指令从旧到新的优先级进行发射，这是因为较旧的指令更有可能拥有较多的相关指令，一次发射能够唤醒更多的指令。对于顺序发射的队列，我们每个周期只会对队列头部的指令进行寄存器占用情况的检查，只会发射队列中的最旧指令，从而保证了这些需要顺序执行的指令的一致性。\n2.3.3 读寄存器 ReadReg 这一级流水线在每条流水线当中都独立存在，负责从物理寄存器当中读出源操作数对应的数值。寄存器堆对于每一条流水线都分配了一个读接口。同时这一级也会接收执行级和写回级前递的信息，用于实现指令的背靠背执行的前递信号传递。 发生前递时，我们会对于前递的寄存器号进行比较。于我们比较的是物理寄存器地址，必定保证写相关寄存器的指令最多只会存在一个，因此可以使用独热码的判命中逻辑，这节约了一定的逻辑复杂度。\n如果是算术流水线的读寄存器阶段，还会进行相关指令的唤醒。在本级进行唤醒，能够保证下一拍相关指令进入readreg级，从而直接从算术执行级当中获得前递的数据，从而保证了指令的背靠背执行。\n2.3.4 算术流水线 Arithmetic 算术流水线是CPU执行过程当中，访问最频繁的流水线。在算术流水线当中，我们的CPU会进行算术和分支指令的执行过程。考虑到这两类指令需要的元器件数目并不多，可以分配多条算术流水线用于这类指令的执行。\n由于我们的前端取指深度为2，后端也应该分配两条算术流水线，以保证算术密集型指令集当中，CPU后端理论能够持续维持双发射的算术指令提交行为。我们在算术指令密集的bitcount等测试集当中，获得了1.2以上的IPC，这证明了我们运算流水线双发+背靠背执行逻辑的可靠性。\n2.3.5 乘除流水线 Muldiv 用于乘除指令与特权指令的执行，分为三级。拆分成多个流水级的主要原因是需要实现乘法运算的流水化。\n对于乘法运算，我们使用xilinx ip搭载了一个三级流水的乘法器，实现了乘法运算的流水化，这使得我们在执行大量乘法运算的时候，能够实现完全的流水化提交过程，优化了CPU的执行效率。\n对于除法运算，我们使用xilinx ip实现了除法器，并在乘除流水线的第一级中进行阻塞执行，考虑到除法指令在实际程序中的占比较低，阻塞式的执行逻辑并不会对于我们的执行效率产生过大影响。\n对于特权指令，我们会将写指令放入特权缓存PrivBuffer当中，并阻塞后续所有特权指令，直到后端ROB进行提交的时候，才使得相关的非普通寄存器更改生效。这样的提交逻辑能够有效保证特权指令配置的一致性，防止特权指令提早对于处理器状态进行更改，并做到了较低的逻辑复杂度，能够更好的优化特权指令提交的复杂度。\n2.3.6 访存流水线 Memory 访存流水线是后端流水线当中最重要的一条，也是设计难度最高的一条。\n对于访存指令，某些访存指令会对处理器状态进行修改，因为其对处理器状态产生的影响不好撤销，所以当执行这些指令时，使用Store Buffer(写缓存)对这种类型的访存指令进行暂存，只有当提交时，才会回传至访存流水线真正执行。\n考虑到硬件复杂度和频率要求，我们设计了多级流水线以提高频率。\n2.3.6.1 Mem0 这一级用于计算访存的虚地址以及TLB的相关信息。\n按照2.2.2.2 TLB提到的同步读取的TLB设计，我们会在本级计算vaddr，并发送至TLB，由TLB进行翻译。\n若是直接地址翻译或直接地址映射，直接将得到的物理地址传递给Mem1级 若是映射地址翻译，给TLB表项发地址，得到命中信息并传递给Mem1级 2.3.6.2 Mem1 在这一级中会选择接受是已提交的访存指令还是Mem0传递而来的指令。在仲裁两条指令的时候，我们会优先选择已提交的访存指令进行执行，从而防止了因为缓存满而导致的阻塞。\n除此之外，Mem1级还会对于TLB相关信息进行维护，逻辑如下：\n在此级中把命中信息发送至TLB，读出命中表项，翻译出paddr；并且判断是否存在TLB相关例外 vaddr发送至D-Cache，索引D-Cache的Tag-sram和Data-sram 2.3.6.3 Mem2 将paddr发送至D-Cache，判定是否命中，若不命中则进入阻塞状态，并与主存利用axi接口交互取出Cache缺失行，若命中则执行可执行的访存指令 可执行访存指令：cached load指令，回滚访存指令 不可执行访存指令：uncached load指令、store指令、原子访存指令和cacop指令。对于这些指令，将其push进Store Buffer 对于cached load指令，我们将从D-Cache中读出的数据传递下去，在写回级进行前递判断，进而降低mem2的硬件复杂度 2.3.6.4 写缓存 Store Buffer 在乱序处理器当中，为了保证处于推测态的访存指令不会对外部状态进行更改，我们使用了写缓存Store Buffer来维护。\n当接收到ROB的提交后，会将写缓存内的信息通过Mem1级重新回流到访存流水线当中。 由于Mem1需要同时接受来自Mem0的数据和来自写缓存的数据，当Mem0向Mem1发送数据时，还会与写缓存发送的数据进行竞争，优先让写缓存内数据进行访存。 当发生flush时，Store Buffer直接清空即可 2.3.6.5 数据(指令)缓存 Cache 每路的组织形式如下，在我们的设计中index = 8。\nLine $0$ bank 0 bank 1 bank 2 bank 3 valid dirty Tag 32 b 32 b 32 b 32 b 1 b 1 b (32 - index) b \u0026hellip;\nLine $2^{index} - 1$ bank 0 bank 1 bank 2 bank 3 valid dirty Tag 32 b 32 b 32 b 32 b 1 b 1 b (32 - index) b I-Cache和D-Cache采取了同样的组织形式，只是I-Cache取消了dirty位；bank在I-Cache代表了指令，在D-Cache中代表了数据。\n为了降低访存复杂度，我们着重设计了访存的状态机，为了获得优秀的硬件复杂度将复杂流程拆分。\n具体状态分为：idle(闲置状态，判断命中)、uncached_read、uncached_write、check_dirty、writeback、replace_line，其中I-Cache无关于写操作的状态\n2.3.7 写回 WriteBack 这一级用于写物理寄存器，更新rob当中对应的提交信息，并更新发射队列当中的寄存器占用状态。\n对于访存流水线，在我们原先的设计当中，推测唤醒会导致大量控制信号串行，从而导致关键路径产生、频率下降。因此，为了时序考虑，直到这一级才会对与访存指令相关的指令进行唤醒。在这一逻辑下，我们的IPC从原先的0.84降至0.78，但我们的频率由65MHz升至了83MHz，相较之下提升幅度达到了18%，因此我们取消了推测唤醒的设计，改为写回级唤醒。\n2.3.8 提交 Commit 这一级用于进行最终的提交，解除对于CPU资源的占用，并解除寄存器的推测态。\n解除对于上一个物理寄存器的占用（opreg），并将opreg对应的寄存器编号插入到空闲寄存器列表freelist 更新aRAT的映射关系，aRAT当中存储的是由已经提交的指令构成的、不涉及推测态指令的寄存器映射表 对于包括分支、访存、特权在内的部分非算术指令，由于分支预测器更新限制、写缓存入队限制等原因，我们在检测到这些指令的时候，不会进行双指令的提交。假如检测到分支预测失败或例外，还会向冲刷控制器发出冲刷请求。 当发生流水线清空的时候，首先向冲刷控制器发出请求。冲刷控制器会延迟一拍后，对于各个流水线及功能部件发出冲刷信号，并令重命名相关部件进行状态恢复。具体而言，状态恢复时，会将aRAT赋值给cRAT，清空rob当中的所有表项，并将freelist的尾指针置为头指针位置。 在提交级，我们通过ROB重排序缓存，成功实现了乱序执行结果的顺序写回过程，保证了乱序CPU在执行上的一致性，通过乱序架构的设计，我们的CPU达到了良好的性能表现。\n3. 参考文献 [1] J. Ye, and L. Xi, PUA-MIPS, https://github.com/Clo91eaf/PUA-MIPS, 2023\n[2] Z. Ma, LA32R-pipeline-scala, https://github.com/MaZirui2001/LA32R-pipeline-scala, 2023\n[3] H. Gao, and M. Liu, NOP-Core, https://github.com/NOP-Processor/NOP-Core, 2023\n[4] Y. Zhou, S. Chen, X. Liu and J. Chen, Nontrivial-mips,https://github.com/trivialmips/nontrivial-mips, 2019\n[5] W. Wang, and J. Xing, CPU Design and Practice, Beijing: China Machine Press, 2021\n[6] Y. Yao, SuperScalar RISC Processor Design, Beijing: Tsinghua University Press, 2014\n","date":"2024-08-14T00:00:00Z","image":"https://crpboy.github.io/p/nscscc-2024-report/cover_hu6374802966040036931.png","permalink":"https://crpboy.github.io/p/nscscc-2024-report/","title":"NSCSCC2024决赛汇报文档"},{"content":"原题链接\n考虑用主席树+倍增+dfn维护\n首先，当$p\\in[l,r]$，或者p的祖先和子树内均有点$x\\in[l,r]$的时候，答案必为0。\n除去以上情况，这些点要么都在我的祖先的子树（且p不在这些子树中）内，要么都在p的子树内\n祖先情况 需要找到我的一个祖先点x满足： $[l,r]$的点都不在点x的子树内\nx是满足第一种情况的最高点\n考虑用倍增维护，主席树查询$[l,r]$上的和即可\n其中，主席树对编号开点，以dfn作为插入的先后顺序\n或者需要找到一个不处于p子树内的点x满足： x为所有$y\\in[l,r]$的lca\n点p不在x的子树内\n直接倍增判断是否符合答案即可，最终答案就是x到p的路径长度\n对于子树情况 需要找到p的子树内的一个节点x满足： $[l,r]$的点都在点x的子树内\nx是满足第一种情况的最低点\n怎样找到x？随便挑一个点$y\\in[l,r]$，我要的答案点x一定在它到$p$的路径上\n那么直接倍增跳就好了\n时间复杂度$O(n \\log^2 n)$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; #define dd ch=getchar() int read() { char dd;int x=0;bool f=false; while(!isdigit(ch))f|=ch==\u0026#39;-\u0026#39;,dd; while(isdigit(ch))x=x*10+ch-48,dd; return f?-x:x; } #undef dd void write(int x) { if(x\u0026lt;0)x=-x,putchar(\u0026#39;-\u0026#39;); if(x\u0026gt;9)write(x/10); putchar(x%10+48); } #define writesp(x) (write(x),putchar(\u0026#39; \u0026#39;)) #define writeln(x) (write(x),putchar(\u0026#39;\\n\u0026#39;)) const int N=2e5+5; int n,q; struct node { int v,w,nxt; }a[N\u0026lt;\u0026lt;1]; int head[N],cnt=0; void add(int u,int v,int w) { a[++cnt].v=v; a[cnt].w=w; a[cnt].nxt=head[u]; head[u]=cnt; } int tot=0; int rt[N],t[N*50],ls[N*50],rs[N*50],fa[N][25]; void push_up(int p) { t[p]=0; if(ls[p])t[p]+=t[ls[p]]; if(rs[p])t[p]+=t[rs[p]]; } int modify(int pre,int l,int r,int pos) { int p=++tot; ls[p]=ls[pre],rs[p]=rs[pre]; if(l==r){t[p]=1;return p;} int mid=(l+r)\u0026gt;\u0026gt;1; if(pos\u0026lt;=mid)ls[p]=modify(ls[pre],l,mid,pos); else rs[p]=modify(rs[pre],mid+1,r,pos); push_up(p); return p; } int query(int p,int l,int r,int L,int R) { if(!p)return 0; if(L\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=R)return t[p]; int mid=(l+r)\u0026gt;\u0026gt;1,ans=0; if(L\u0026lt;=mid)ans+=query(ls[p],l,mid,L,R); if(mid\u0026lt;R)ans+=query(rs[p],mid+1,r,L,R); return ans; } int size[N],dep[N],deep[N],dfn[N],num=0; void dfs(int u) { size[u]=1; dfn[u]=++num; rt[num]=modify(rt[num-1],1,n,u); for(int i=1;i\u0026lt;=20;i++) fa[u][i]=fa[fa[u][i-1]][i-1]; for(int i=head[u];i;i=a[i].nxt) { int v=a[i].v,w=a[i].w; if(v==fa[u][0])continue; dep[v]=dep[u]+w;deep[v]=deep[u]+1; fa[v][0]=u; dfs(v); size[u]+=size[v]; } } int getres(int x,int l,int r) { return query(rt[dfn[x]+size[x]-1],1,n,l,r)-query(rt[dfn[x]-1],1,n,l,r); } int lca(int x,int y) { if(deep[x]\u0026lt;deep[y])swap(x,y); for(int i=20;i\u0026gt;=0;i--) if(deep[fa[x][i]]\u0026gt;=deep[y]) x=fa[x][i]; if(x==y)return x; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]!=fa[y][i]) x=fa[x][i],y=fa[y][i]; return fa[x][0]; } int query1(int x,int l,int r) { int o=x; if(getres(o,l,r))return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;!getres(fa[x][i],l,r)) x=fa[x][i]; x=fa[x][0]; if(!x)return 0; return dep[o]-dep[x]; } int query2(int x,int l,int r) { int o=x;x=l; if(getres(o,l,r)!=r-l+1)return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;getres(fa[x][i],l,r)!=r-l+1) x=fa[x][i]; if(getres(x,l,r)!=r-l+1)x=fa[x][0]; if(!x)return 0; return dep[x]-dep[o]; } int query3(int x,int l,int r) { int o=x;x=l; if(getres(o,l,r))return 0; for(int i=20;i\u0026gt;=0;i--) if(fa[x][i]\u0026amp;\u0026amp;getres(fa[x][i],l,r)!=r-l+1) x=fa[x][i]; if(getres(x,l,r)!=r-l+1)x=fa[x][0]; if(!x||getres(x,o,o)==1)return 0; return dep[o]+dep[x]-dep[lca(x,o)]*2; } int main() { //\tfreopen(\u0026#34;6071.in\u0026#34;,\u0026#34;r\u0026#34;,stdin); //\tfreopen(\u0026#34;6071.out\u0026#34;,\u0026#34;w\u0026#34;,stdout); n=read(),q=read(); for(int i=1,u,v,w;i\u0026lt;n;i++) u=read(),v=read(),w=read(),add(u,v,w),add(v,u,w); dfs(1); int lasans=0; while(q--) { int p=read()^lasans,l=read()^lasans,r=read()^lasans; writeln(lasans=max(query1(p,l,r),max(query2(p,l,r),query3(p,l,r)))); } return 0; } ","date":"2022-11-16T00:00:00Z","image":"https://crpboy.github.io/p/luogu-p6071-solution/cover_hu478156444678039639.png","permalink":"https://crpboy.github.io/p/luogu-p6071-solution/","title":"洛谷P6071『MdOI R1』Treequery"}]